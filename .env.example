# Copy this file to .env and fill in the values

# NOTE: The only required value is OPENAI_API_KEY. The app should work if the other values 
# are left as is or not defined at all. 
OPENAI_API_KEY="" # your OpenAI API key 
SERPER_API_KEY="" # your Google Serper API key (for web searches). If you don't set this,
# a community key will be used, which may have run out of credits by the time you use it.
# You can get a free key without a credit card here: https://serper.dev/

# Mode to use if none is specified in the query
DEFAULT_MODE="/docs" # or "/web" | "/quotes" | "/details" | "/chat" | "/research"

# Variables controlling whether the Streamlit app imposes some functionality restrictions
BYPASS_SETTINGS_RESTRICTIONS="" # whether to immediately allow all settings (any non-empty string means true)
BYPASS_SETTINGS_RESTRICTIONS_PASSWORD="" # what to enter in the OpenAI API key field to bypass settings 
# restrictions (if BYPASS_SETTINGS_RESTRICTIONS is true or if user enters their own API key, this 
# becomes irrelevant, as full settings access is already granted). Recommendation: for local use,
# the easiest thing to do is to leave this blank but set BYPASS_SETTINGS_RESTRICTIONS to "yep".

# If you are NOT using Azure, the following setting determines the chat model
# NOTE: in the Streamlit app, you can change the model and temperature on the fly
MODEL_NAME="gpt-3.5-turbo-1106" # another example: "gpt-4-1106-preview"
CONTEXT_LENGTH="16000" # you can also make it lower than the actual context length

# If you are using Azure, uncomment the following settings and fill in the values
# OPENAI_API_TYPE="azure" # yours may be different 
# OPENAI_API_BASE="https://techops.openai.azure.com" # yours may be different 
# OPENAI_API_VERSION="2023-05-15" # or whichever version you're using
# CHAT_DEPLOYMENT_NAME="gpt-35-turbo" # your deployment name for the chat model you want to use
# EMBEDDINGS_DEPLOYMENT_NAME="text-embedding-ada-002" # your deployment name for the embedding model

TEMPERATURE="0.3" # 0 to 2, higher means more random, lower means more conservative (>1.6 is jibberish)
LLM_REQUEST_TIMEOUT="3" # seconds to wait before request to the LLM service should be considered timed
# out and the bot should retry sending the request (a few times with exponential back-off).
# For Azure, it seems that a slightly longer timeout is needed, about 9 seconds.

# Whether to use Playwright for more reliable web scraping (any non-empty string means true)
# It's recommended to use Playwright but it may not work in all environments and requires
# a small amount of setup (mostly just running "playwright install" - you will be prompted)
USE_PLAYWRIGHT="" 

DEFAULT_COLLECTION_NAME="docdocgo-documentation" # name of the initially selected collection

## There are two ways to use the Chroma vector database: using a local database or via HTTP 
## (e.g. by running it in a Docker container. The default is the local option. While it's the
## simplest way to get started, the HTTP option is more robust and scalable.

## The following item is only relevant if you want to use a local Chroma db
VECTORDB_DIR="chroma/" # directory of your doc database

## The following items are only relevant if you want to run Chroma in a Docker container
USE_CHROMA_VIA_HTTP="" # whether to use Chroma via HTTP (any non-empty string means true)
CHROMA_SERVER_AUTH_CREDENTIALS="" # choose your own (must be the same as in your Chroma Docker container)
CHROMA_SERVER_HOST="localhost" # IP address of your Chroma server
CHROMA_SERVER_HTTP_PORT="8000" # port your Chroma server is listening on

## The following items are only relevant for ingesting docs
COLLECTON_NAME_FOR_INGESTED_DOCS="" # collection name for the docs you want to ingest
DOCS_TO_INGEST_DIR_OR_FILE="" # path to directory or single file with your docs to ingest

## The following item is only relevant if running the flask server
DOCDOCGO_API_KEY="" # choose your own 

## Additional options, used in development (any non-empty string means true)
RERAISE_EXCEPTIONS="" # don't keep convo going if an exception is raised, just reraise it
PRINT_STANDALONE_QUERY="" # print query used for the retriever
PRINT_QA_PROMPT="" # print the prompt used for the final response (if asking about your docs)
PRINT_CONDENSE_QUESTION_PROMPT="" # print the prompt used to condense the question
PRINT_SIMILARITIES="" # print the similarities between the query and the docs
PRINT_WEBSEARCHER_PROMPT="" # print the prompt used for the final websearcher response
INITIAL_TEST_QUERY_STREAMLIT="" # auto-run as the first query in Streamlit
